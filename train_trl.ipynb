{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_dir, '..', 'llm-negotiations')))\n",
    "from envs.negotiation_env import NegotiationEnv\n",
    "from trainer.GRPOEnvTrainer import GRPOEnvTrainer\n",
    "from trainer.utils import get_default_grpo_config\n",
    "import hydra\n",
    "from omegaconf import DictConfig, open_dict, OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from simulator.games import Game\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from helpers.utils import unpack_nested_yaml, fill_defaults, get_inference_root_overrides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from helpers.utils import unpack_nested_yaml, get_inference_root_overrides, fill_defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      " {\n",
      "    \"num_negotiations\": 17000,\n",
      "    \"checkpoint_frequency\": 2500,\n",
      "    \"dataset_name\": \"LuckyLukke/negotio_REFUEL_8B_twosided\",\n",
      "    \"onesided\": false,\n",
      "    \"seed\": 188,\n",
      "    \"game\": {\n",
      "        \"_target_\": \"simulator.games.Game\",\n",
      "        \"name\": \"generic-rental-agreement\",\n",
      "        \"issues\": [\n",
      "            \"gen-ra-rent.yaml\"\n",
      "        ],\n",
      "        \"issue_weights\": [\n",
      "            [\n",
      "                1\n",
      "            ],\n",
      "            [\n",
      "                1\n",
      "            ]\n",
      "        ],\n",
      "        \"scale\": [\n",
      "            100,\n",
      "            100\n",
      "        ],\n",
      "        \"description\": \"A landlord and a prospective tenant are negotiating a rental agreement.\",\n",
      "        \"sides\": [\n",
      "            \"You are an advisor representing the best interests of the landlord. Your main goal is to negotiate the best possible agreement for the landlord based on the information in the payoff tables. The numbers in the payoff tables show how valuable each outcome is to you. You can trust that the payoffs assigned to the different options in your table are accurate. Do not bring up any issues that are not specifically noted in your payoff table. It is possible that there is only 1 issue.\",\n",
      "            \"You are an advisor representing the best interests of the tenant. Your main goal is to negotiate the best possible agreement for the tenant based on the information in the payoff tables. The numbers in the payoff tables show how valuable each outcome is to you. You can trust that the payoffs assigned to the different options in your table are accurate. Do not bring up any issues that are not specifically noted in your payoff table. It is possible that there is only 1 issue.\"\n",
      "        ],\n",
      "        \"parties\": [\n",
      "            \"Landlord\",\n",
      "            \"Tenant\"\n",
      "        ],\n",
      "        \"rules_prompt\": \"Never forget the following negotiation rules:\",\n",
      "        \"rules\": [\n",
      "            \"Your total payoff is the sum of your payoffs on all issues. Higher payoffs are better than lower payoffs.\",\n",
      "            \"A valid agreement occurs only when all issues are decided. Partial agreements result in a total payoff to you of zero.\",\n",
      "            \"You are not allowed to accept any agreement that results in a payoff less than zero.\",\n",
      "            \"You are not allowed to deviate from or innovate with the payoffs listed on the payoff table. In other words, you cannot change your payoffs.\",\n",
      "            \"No side payments are allowed. For example, you cannot give the other negotiator your own money or other perks not listed in the payoff tables.\",\n",
      "            \"You may describe issues and elaborate on them as you see fit. However, you are not allowed to invent additional issues.\",\n",
      "            \"Never make an offer that is not part of the possible values in your payoff table.\"\n",
      "        ]\n",
      "    },\n",
      "    \"agent_1\": {\n",
      "        \"_target_\": \"simulator.agents.NegotiationAgent\",\n",
      "        \"model\": {\n",
      "            \"_target_\": \"models.huggingface_model.HuggingFaceModel\",\n",
      "            \"model_provider\": \"huggingface\",\n",
      "            \"model_name\": \"meta-llama/Llama-3.2-1B-Instruct\",\n",
      "            \"use_vllm\": true,\n",
      "            \"temperature\": 0.9,\n",
      "            \"top_p\": 0.95,\n",
      "            \"repetition_penalty\": 1.15\n",
      "        },\n",
      "        \"internal_description\": {\n",
      "            \"name\": \"You\"\n",
      "        },\n",
      "        \"external_description\": {\n",
      "            \"name\": \"Representative\"\n",
      "        }\n",
      "    },\n",
      "    \"agent_2\": {\n",
      "        \"_target_\": \"simulator.agents.NegotiationAgent\",\n",
      "        \"model\": {\n",
      "            \"_target_\": \"models.huggingface_model.HuggingFaceModel\",\n",
      "            \"model_provider\": \"huggingface\",\n",
      "            \"model_name\": \"meta-llama/Llama-3.2-1B-Instruct\",\n",
      "            \"temperature\": 0.9,\n",
      "            \"top_p\": 0.95,\n",
      "            \"use_vllm\": true,\n",
      "            \"repetition_penalty\": 1.15\n",
      "        },\n",
      "        \"internal_description\": {\n",
      "            \"name\": \"You\"\n",
      "        },\n",
      "        \"external_description\": {\n",
      "            \"name\": \"Representative\"\n",
      "        }\n",
      "    },\n",
      "    \"negotiation_protocol\": {\n",
      "        \"max_rounds\": 5,\n",
      "        \"extract_table\": false,\n",
      "        \"save_folder\": \"/cluster/home/fraluca/negotio2/llm-negotiations/data/results/llama\",\n",
      "        \"start_agent_index\": 0,\n",
      "        \"format_as_dialogue\": false\n",
      "    },\n",
      "    \"refuel\": false,\n",
      "    \"evaluate\": true,\n",
      "    \"experiment_sleep_time\": 1,\n",
      "    \"side\": 0\n",
      "}\n",
      "num_negotiations: 17000\n",
      "checkpoint_frequency: 2500\n",
      "dataset_name: LuckyLukke/negotio_REFUEL_8B_twosided\n",
      "onesided: false\n",
      "seed: 188\n",
      "game:\n",
      "  _target_: simulator.games.Game\n",
      "  name: generic-rental-agreement\n",
      "  issues:\n",
      "  - gen-ra-rent.yaml\n",
      "  issue_weights:\n",
      "  - - 1\n",
      "  - - 1\n",
      "  scale:\n",
      "  - 100\n",
      "  - 100\n",
      "  description: A landlord and a prospective tenant are negotiating a rental agreement.\n",
      "  sides:\n",
      "  - You are an advisor representing the best interests of the landlord. Your main\n",
      "    goal is to negotiate the best possible agreement for the landlord based on the\n",
      "    information in the payoff tables. The numbers in the payoff tables show how valuable\n",
      "    each outcome is to you. You can trust that the payoffs assigned to the different\n",
      "    options in your table are accurate. Do not bring up any issues that are not specifically\n",
      "    noted in your payoff table. It is possible that there is only 1 issue.\n",
      "  - You are an advisor representing the best interests of the tenant. Your main goal\n",
      "    is to negotiate the best possible agreement for the tenant based on the information\n",
      "    in the payoff tables. The numbers in the payoff tables show how valuable each\n",
      "    outcome is to you. You can trust that the payoffs assigned to the different options\n",
      "    in your table are accurate. Do not bring up any issues that are not specifically\n",
      "    noted in your payoff table. It is possible that there is only 1 issue.\n",
      "  parties:\n",
      "  - Landlord\n",
      "  - Tenant\n",
      "  rules_prompt: 'Never forget the following negotiation rules:'\n",
      "  rules:\n",
      "  - Your total payoff is the sum of your payoffs on all issues. Higher payoffs are\n",
      "    better than lower payoffs.\n",
      "  - A valid agreement occurs only when all issues are decided. Partial agreements\n",
      "    result in a total payoff to you of zero.\n",
      "  - You are not allowed to accept any agreement that results in a payoff less than\n",
      "    zero.\n",
      "  - You are not allowed to deviate from or innovate with the payoffs listed on the\n",
      "    payoff table. In other words, you cannot change your payoffs.\n",
      "  - No side payments are allowed. For example, you cannot give the other negotiator\n",
      "    your own money or other perks not listed in the payoff tables.\n",
      "  - You may describe issues and elaborate on them as you see fit. However, you are\n",
      "    not allowed to invent additional issues.\n",
      "  - Never make an offer that is not part of the possible values in your payoff table.\n",
      "agent_1:\n",
      "  _target_: simulator.agents.NegotiationAgent\n",
      "  model:\n",
      "    _target_: models.huggingface_model.HuggingFaceModel\n",
      "    model_provider: huggingface\n",
      "    model_name: meta-llama/Llama-3.2-1B-Instruct\n",
      "    use_vllm: true\n",
      "    temperature: 0.9\n",
      "    top_p: 0.95\n",
      "    repetition_penalty: 1.15\n",
      "  internal_description:\n",
      "    name: You\n",
      "  external_description:\n",
      "    name: Representative\n",
      "agent_2:\n",
      "  _target_: simulator.agents.NegotiationAgent\n",
      "  model:\n",
      "    _target_: models.huggingface_model.HuggingFaceModel\n",
      "    model_provider: huggingface\n",
      "    model_name: meta-llama/Llama-3.2-1B-Instruct\n",
      "    temperature: 0.9\n",
      "    top_p: 0.95\n",
      "    use_vllm: true\n",
      "    repetition_penalty: 1.15\n",
      "  internal_description:\n",
      "    name: You\n",
      "  external_description:\n",
      "    name: Representative\n",
      "negotiation_protocol:\n",
      "  max_rounds: 5\n",
      "  extract_table: false\n",
      "  save_folder: /cluster/home/fraluca/negotio2/llm-negotiations/data/results/llama\n",
      "  start_agent_index: 0\n",
      "  format_as_dialogue: false\n",
      "refuel: false\n",
      "evaluate: true\n",
      "experiment_sleep_time: 1\n",
      "side: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from envs.negotiation_env import NegotiationEnv\n",
    "\n",
    "\n",
    "# If running in Jupyter/IPython, clear sys.argv to avoid argument parsing issues\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = [sys.argv[0]]\n",
    "\n",
    "\n",
    "# # Manually initialize Hydra\n",
    "if GlobalHydra.instance().is_initialized():\n",
    "    GlobalHydra.instance().clear()\n",
    "    \n",
    "# Explicitly initialize Hydra - this is what was missing in your code\n",
    "initialize(version_base=None, config_path=\"../llm-negotiations/configs\")\n",
    "\n",
    "# Now you can call compose()\n",
    "cfg = hydra.compose(config_name=\"inference_root\",  return_hydra_config=True)\n",
    "\n",
    "HydraConfig().cfg = cfg\n",
    "\n",
    "with open_dict(cfg):\n",
    "    # Set the working directory to the parent directory\n",
    "    cfg.work_dir = os.path.abspath(os.path.join(os.getcwd(), \"../llm-negotiations\"))\n",
    "\n",
    "# print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_config(cfg: DictConfig):\n",
    "  \n",
    "        with open_dict(cfg['experiment']):\n",
    "            # unpack nested yaml files\n",
    "            _ = unpack_nested_yaml(cfg['experiment'])\n",
    "            # check if any keys are missing and update default run-time overrides\n",
    "         \n",
    "            overrides = get_inference_root_overrides(cfg, \"/cluster/home/fraluca/negotio2/llm-negotiations/configs/inference_root.yaml\")\n",
    "            _ = fill_defaults(cfg['experiment'], root_overrides=overrides, defaults_file=\"/cluster/home/fraluca/negotio2/llm-negotiations/configs/negotiation_defaults.yaml\")\n",
    "            # unpack default yaml files (if any)\n",
    "            _ = unpack_nested_yaml(cfg['experiment'])\n",
    "            # update model constructors in case of model overrides\n",
    "\n",
    "            config = cfg.experiment\n",
    "\n",
    "            config_dict = OmegaConf.to_container(config, resolve=True)\n",
    "            print(\"Config:\\n\", json.dumps(config_dict, indent=4))\n",
    "\n",
    "            return config\n",
    "\n",
    "\n",
    "\n",
    "# Call your processing function\n",
    "config = get_config(cfg)\n",
    "\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'simulator.games.Game', 'name': 'generic-rental-agreement', 'issues': ['gen-ra-rent.yaml'], 'issue_weights': [[1], [1]], 'scale': [100, 100], 'description': 'A landlord and a prospective tenant are negotiating a rental agreement.', 'sides': ['You are an advisor representing the best interests of the landlord. Your main goal is to negotiate the best possible agreement for the landlord based on the information in the payoff tables. The numbers in the payoff tables show how valuable each outcome is to you. You can trust that the payoffs assigned to the different options in your table are accurate. Do not bring up any issues that are not specifically noted in your payoff table. It is possible that there is only 1 issue.', 'You are an advisor representing the best interests of the tenant. Your main goal is to negotiate the best possible agreement for the tenant based on the information in the payoff tables. The numbers in the payoff tables show how valuable each outcome is to you. You can trust that the payoffs assigned to the different options in your table are accurate. Do not bring up any issues that are not specifically noted in your payoff table. It is possible that there is only 1 issue.'], 'parties': ['Landlord', 'Tenant'], 'rules_prompt': 'Never forget the following negotiation rules:', 'rules': ['Your total payoff is the sum of your payoffs on all issues. Higher payoffs are better than lower payoffs.', 'A valid agreement occurs only when all issues are decided. Partial agreements result in a total payoff to you of zero.', 'You are not allowed to accept any agreement that results in a payoff less than zero.', 'You are not allowed to deviate from or innovate with the payoffs listed on the payoff table. In other words, you cannot change your payoffs.', 'No side payments are allowed. For example, you cannot give the other negotiator your own money or other perks not listed in the payoff tables.', 'You may describe issues and elaborate on them as you see fit. However, you are not allowed to invent additional issues.', 'Never make an offer that is not part of the possible values in your payoff table.']}\n",
      "WARNING 03-28 11:22:27 config.py:1651] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 03-28 11:22:27 arg_utils.py:862] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 03-28 11:22:27 config.py:999] Chunked prefill is enabled with max_num_batched_tokens=512.\n",
      "INFO 03-28 11:22:27 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.2-1B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "INFO 03-28 11:22:30 model_runner.py:915] Starting to load model meta-llama/Llama-3.2-1B-Instruct...\n"
     ]
    },
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'models.huggingface_model.HuggingFaceModel':\nOutOfMemoryError('CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 10.57 GiB of which 11.06 MiB is free. Including non-PyTorch memory, this process has 10.55 GiB memory in use. Of the allocated memory 10.21 GiB is allocated by PyTorch, with 23.47 MiB allocated in private pools (e.g., CUDA Graphs), and 55.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)')\nfull_key: experiment.agent_1.model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m _target_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<attrs generated init models.huggingface_model.HuggingFaceModel>:19\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, model_key, model_key_path, model_key_name, temperature, context_max_tokens, model_provider, model_name, tokenizer, model, half_precision, role_mapping, top_p, repetition_penalty, llm, reduce_memory, use_vllm, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__attrs_post_init__()\n",
      "File \u001b[0;32m~/negotio2/llm-negotiations/models/huggingface_model.py:55\u001b[0m, in \u001b[0;36mHuggingFaceModel.__attrs_post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm \u001b[39m=\u001b[39m LLM(\n\u001b[1;32m     56\u001b[0m             model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[1;32m     57\u001b[0m             tokenizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[1;32m     58\u001b[0m             \u001b[39m# dtype=torch.bfloat16,\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m             dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhalf\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     60\u001b[0m         )\n\u001b[1;32m     61\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/entrypoints/llm.py:177\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_context_len_to_capture, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m engine_args \u001b[39m=\u001b[39m EngineArgs(\n\u001b[1;32m    156\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    157\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    176\u001b[0m )\n\u001b[0;32m--> 177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_engine \u001b[39m=\u001b[39m LLMEngine\u001b[39m.\u001b[39;49mfrom_engine_args(\n\u001b[1;32m    178\u001b[0m     engine_args, usage_context\u001b[39m=\u001b[39;49mUsageContext\u001b[39m.\u001b[39;49mLLM_CLASS)\n\u001b[1;32m    179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_counter \u001b[39m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/engine/llm_engine.py:538\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m engine \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    539\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_config\u001b[39m.\u001b[39;49mto_dict(),\n\u001b[1;32m    540\u001b[0m     executor_class\u001b[39m=\u001b[39;49mexecutor_class,\n\u001b[1;32m    541\u001b[0m     log_stats\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m engine_args\u001b[39m.\u001b[39;49mdisable_log_stats,\n\u001b[1;32m    542\u001b[0m     usage_context\u001b[39m=\u001b[39;49musage_context,\n\u001b[1;32m    543\u001b[0m     stat_loggers\u001b[39m=\u001b[39;49mstat_loggers,\n\u001b[1;32m    544\u001b[0m )\n\u001b[1;32m    546\u001b[0m \u001b[39mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/engine/llm_engine.py:305\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, decoding_config, observability_config, prompt_adapter_config, executor_class, log_stats, usage_context, stat_loggers, input_registry, step_return_finished_only)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_processor \u001b[39m=\u001b[39m input_registry\u001b[39m.\u001b[39mcreate_input_processor(\n\u001b[1;32m    303\u001b[0m     model_config)\n\u001b[0;32m--> 305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_executor \u001b[39m=\u001b[39m executor_class(\n\u001b[1;32m    306\u001b[0m     model_config\u001b[39m=\u001b[39;49mmodel_config,\n\u001b[1;32m    307\u001b[0m     cache_config\u001b[39m=\u001b[39;49mcache_config,\n\u001b[1;32m    308\u001b[0m     parallel_config\u001b[39m=\u001b[39;49mparallel_config,\n\u001b[1;32m    309\u001b[0m     scheduler_config\u001b[39m=\u001b[39;49mscheduler_config,\n\u001b[1;32m    310\u001b[0m     device_config\u001b[39m=\u001b[39;49mdevice_config,\n\u001b[1;32m    311\u001b[0m     lora_config\u001b[39m=\u001b[39;49mlora_config,\n\u001b[1;32m    312\u001b[0m     speculative_config\u001b[39m=\u001b[39;49mspeculative_config,\n\u001b[1;32m    313\u001b[0m     load_config\u001b[39m=\u001b[39;49mload_config,\n\u001b[1;32m    314\u001b[0m     prompt_adapter_config\u001b[39m=\u001b[39;49mprompt_adapter_config,\n\u001b[1;32m    315\u001b[0m     observability_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservability_config,\n\u001b[1;32m    316\u001b[0m )\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_config\u001b[39m.\u001b[39membedding_mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/executor/executor_base.py:47\u001b[0m, in \u001b[0;36mExecutorBase.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, prompt_adapter_config, observability_config)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservability_config \u001b[39m=\u001b[39m observability_config\n\u001b[0;32m---> 47\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_executor()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/executor/gpu_executor.py:40\u001b[0m, in \u001b[0;36mGPUExecutor._init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriver_worker\u001b[39m.\u001b[39minit_device()\n\u001b[0;32m---> 40\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdriver_worker\u001b[39m.\u001b[39;49mload_model()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/worker/worker.py:182\u001b[0m, in \u001b[0;36mWorker.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_runner\u001b[39m.\u001b[39;49mload_model()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/worker/model_runner.py:917\u001b[0m, in \u001b[0;36mGPUModelRunnerBase.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mwith\u001b[39;00m CudaMemoryProfiler() \u001b[39mas\u001b[39;00m m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m get_model(model_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_config,\n\u001b[1;32m    918\u001b[0m                            device_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_config,\n\u001b[1;32m    919\u001b[0m                            load_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_config,\n\u001b[1;32m    920\u001b[0m                            lora_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlora_config,\n\u001b[1;32m    921\u001b[0m                            parallel_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_config,\n\u001b[1;32m    922\u001b[0m                            scheduler_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscheduler_config,\n\u001b[1;32m    923\u001b[0m                            cache_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_config)\n\u001b[1;32m    925\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_memory_usage \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mconsumed_memory\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/model_loader/__init__.py:19\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_config, load_config, device_config, parallel_config, scheduler_config, lora_config, cache_config)\u001b[0m\n\u001b[1;32m     18\u001b[0m loader \u001b[39m=\u001b[39m get_model_loader(load_config)\n\u001b[0;32m---> 19\u001b[0m \u001b[39mreturn\u001b[39;00m loader\u001b[39m.\u001b[39;49mload_model(model_config\u001b[39m=\u001b[39;49mmodel_config,\n\u001b[1;32m     20\u001b[0m                          device_config\u001b[39m=\u001b[39;49mdevice_config,\n\u001b[1;32m     21\u001b[0m                          lora_config\u001b[39m=\u001b[39;49mlora_config,\n\u001b[1;32m     22\u001b[0m                          parallel_config\u001b[39m=\u001b[39;49mparallel_config,\n\u001b[1;32m     23\u001b[0m                          scheduler_config\u001b[39m=\u001b[39;49mscheduler_config,\n\u001b[1;32m     24\u001b[0m                          cache_config\u001b[39m=\u001b[39;49mcache_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/model_loader/loader.py:341\u001b[0m, in \u001b[0;36mDefaultModelLoader.load_model\u001b[0;34m(self, model_config, device_config, lora_config, parallel_config, scheduler_config, cache_config)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39mwith\u001b[39;00m target_device:\n\u001b[0;32m--> 341\u001b[0m     model \u001b[39m=\u001b[39m _initialize_model(model_config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_config,\n\u001b[1;32m    342\u001b[0m                               lora_config, cache_config,\n\u001b[1;32m    343\u001b[0m                               scheduler_config)\n\u001b[1;32m    344\u001b[0m model\u001b[39m.\u001b[39mload_weights(\n\u001b[1;32m    345\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_weights_iterator(model_config\u001b[39m.\u001b[39mmodel,\n\u001b[1;32m    346\u001b[0m                                model_config\u001b[39m.\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m                                    \u001b[39m\"\u001b[39m\u001b[39mfall_back_to_pt_during_load\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    350\u001b[0m                                    \u001b[39mTrue\u001b[39;00m)), )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/model_loader/loader.py:170\u001b[0m, in \u001b[0;36m_initialize_model\u001b[0;34m(model_config, load_config, lora_config, cache_config, scheduler_config)\u001b[0m\n\u001b[1;32m    168\u001b[0m model_class, _ \u001b[39m=\u001b[39m get_model_architecture(model_config)\n\u001b[0;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m build_model(\n\u001b[1;32m    171\u001b[0m     model_class,\n\u001b[1;32m    172\u001b[0m     model_config\u001b[39m.\u001b[39;49mhf_config,\n\u001b[1;32m    173\u001b[0m     cache_config\u001b[39m=\u001b[39;49mcache_config,\n\u001b[1;32m    174\u001b[0m     quant_config\u001b[39m=\u001b[39;49m_get_quantization_config(model_config, load_config),\n\u001b[1;32m    175\u001b[0m     lora_config\u001b[39m=\u001b[39;49mlora_config,\n\u001b[1;32m    176\u001b[0m     multimodal_config\u001b[39m=\u001b[39;49mmodel_config\u001b[39m.\u001b[39;49mmultimodal_config,\n\u001b[1;32m    177\u001b[0m     scheduler_config\u001b[39m=\u001b[39;49mscheduler_config,\n\u001b[1;32m    178\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/model_loader/loader.py:155\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(model_class, hf_config, cache_config, quant_config, lora_config, multimodal_config, scheduler_config)\u001b[0m\n\u001b[1;32m    151\u001b[0m extra_kwargs \u001b[39m=\u001b[39m _get_model_initialization_kwargs(model_class, lora_config,\n\u001b[1;32m    152\u001b[0m                                                 multimodal_config,\n\u001b[1;32m    153\u001b[0m                                                 scheduler_config)\n\u001b[0;32m--> 155\u001b[0m \u001b[39mreturn\u001b[39;00m model_class(config\u001b[39m=\u001b[39;49mhf_config,\n\u001b[1;32m    156\u001b[0m                    cache_config\u001b[39m=\u001b[39;49mcache_config,\n\u001b[1;32m    157\u001b[0m                    quant_config\u001b[39m=\u001b[39;49mquant_config,\n\u001b[1;32m    158\u001b[0m                    \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:391\u001b[0m, in \u001b[0;36mLlamaForCausalLM.__init__\u001b[0;34m(self, config, cache_config, quant_config, lora_config)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlora_config \u001b[39m=\u001b[39m lora_config\n\u001b[0;32m--> 391\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m LlamaModel(config,\n\u001b[1;32m    392\u001b[0m                         cache_config,\n\u001b[1;32m    393\u001b[0m                         quant_config,\n\u001b[1;32m    394\u001b[0m                         lora_config\u001b[39m=\u001b[39;49mlora_config,\n\u001b[1;32m    395\u001b[0m                         prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m get_pp_group()\u001b[39m.\u001b[39mis_last_rank:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:292\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[0;34m(self, config, cache_config, quant_config, lora_config, prefix)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens \u001b[39m=\u001b[39m PPMissingLayer()\n\u001b[0;32m--> 292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_layer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_layer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m make_layers(\n\u001b[1;32m    293\u001b[0m     config\u001b[39m.\u001b[39;49mnum_hidden_layers,\n\u001b[1;32m    294\u001b[0m     \u001b[39mlambda\u001b[39;49;00m prefix: LlamaDecoderLayer(config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    295\u001b[0m                                      cache_config\u001b[39m=\u001b[39;49mcache_config,\n\u001b[1;32m    296\u001b[0m                                      quant_config\u001b[39m=\u001b[39;49mquant_config,\n\u001b[1;32m    297\u001b[0m                                      prefix\u001b[39m=\u001b[39;49mprefix),\n\u001b[1;32m    298\u001b[0m     prefix\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mprefix\u001b[39m}\u001b[39;49;00m\u001b[39m.layers\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m get_pp_group()\u001b[39m.\u001b[39mis_last_rank:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/models/utils.py:247\u001b[0m, in \u001b[0;36mmake_layers\u001b[0;34m(num_hidden_layers, layer_fn, prefix)\u001b[0m\n\u001b[1;32m    243\u001b[0m start_layer, end_layer \u001b[39m=\u001b[39m get_pp_indices(num_hidden_layers,\n\u001b[1;32m    244\u001b[0m                                         get_pp_group()\u001b[39m.\u001b[39mrank_in_group,\n\u001b[1;32m    245\u001b[0m                                         get_pp_group()\u001b[39m.\u001b[39mworld_size)\n\u001b[1;32m    246\u001b[0m modules \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModuleList(\n\u001b[0;32m--> 247\u001b[0m     [PPMissingLayer() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_layer)] \u001b[39m+\u001b[39m [\n\u001b[1;32m    248\u001b[0m         maybe_offload_to_cpu(layer_fn(prefix\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mprefix\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00midx\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    249\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(start_layer, end_layer)\n\u001b[1;32m    250\u001b[0m     ] \u001b[39m+\u001b[39m [PPMissingLayer() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(end_layer, num_hidden_layers)])\n\u001b[1;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m start_layer, end_layer, modules\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/models/utils.py:248\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    243\u001b[0m start_layer, end_layer \u001b[39m=\u001b[39m get_pp_indices(num_hidden_layers,\n\u001b[1;32m    244\u001b[0m                                         get_pp_group()\u001b[39m.\u001b[39mrank_in_group,\n\u001b[1;32m    245\u001b[0m                                         get_pp_group()\u001b[39m.\u001b[39mworld_size)\n\u001b[1;32m    246\u001b[0m modules \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModuleList(\n\u001b[1;32m    247\u001b[0m     [PPMissingLayer() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_layer)] \u001b[39m+\u001b[39m [\n\u001b[0;32m--> 248\u001b[0m         maybe_offload_to_cpu(layer_fn(prefix\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mprefix\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00midx\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    249\u001b[0m         \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_layer, end_layer)\n\u001b[1;32m    250\u001b[0m     ] \u001b[39m+\u001b[39m [PPMissingLayer() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(end_layer, num_hidden_layers)])\n\u001b[1;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m start_layer, end_layer, modules\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:294\u001b[0m, in \u001b[0;36mLlamaModel.__init__.<locals>.<lambda>\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens \u001b[39m=\u001b[39m PPMissingLayer()\n\u001b[1;32m    292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_layer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_layer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m make_layers(\n\u001b[1;32m    293\u001b[0m     config\u001b[39m.\u001b[39mnum_hidden_layers,\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mlambda\u001b[39;00m prefix: LlamaDecoderLayer(config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    295\u001b[0m                                      cache_config\u001b[39m=\u001b[39;49mcache_config,\n\u001b[1;32m    296\u001b[0m                                      quant_config\u001b[39m=\u001b[39;49mquant_config,\n\u001b[1;32m    297\u001b[0m                                      prefix\u001b[39m=\u001b[39;49mprefix),\n\u001b[1;32m    298\u001b[0m     prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mprefix\u001b[39m}\u001b[39;00m\u001b[39m.layers\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m get_pp_group()\u001b[39m.\u001b[39mis_last_rank:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:223\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.__init__\u001b[0;34m(self, config, cache_config, quant_config, prefix)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn \u001b[39m=\u001b[39m LlamaAttention(\n\u001b[1;32m    210\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m    211\u001b[0m     hidden_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mprefix\u001b[39m}\u001b[39;00m\u001b[39m.self_attn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp \u001b[39m=\u001b[39m LlamaMLP(\n\u001b[1;32m    224\u001b[0m     hidden_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden_size,\n\u001b[1;32m    225\u001b[0m     intermediate_size\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mintermediate_size,\n\u001b[1;32m    226\u001b[0m     hidden_act\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mhidden_act,\n\u001b[1;32m    227\u001b[0m     quant_config\u001b[39m=\u001b[39;49mquant_config,\n\u001b[1;32m    228\u001b[0m     bias\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(config, \u001b[39m\"\u001b[39;49m\u001b[39mmlp_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    229\u001b[0m     prefix\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mprefix\u001b[39m}\u001b[39;49;00m\u001b[39m.mlp\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    230\u001b[0m )\n\u001b[1;32m    231\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layernorm \u001b[39m=\u001b[39m RMSNorm(config\u001b[39m.\u001b[39mhidden_size,\n\u001b[1;32m    232\u001b[0m                                eps\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:76\u001b[0m, in \u001b[0;36mLlamaMLP.__init__\u001b[0;34m(self, hidden_size, intermediate_size, hidden_act, quant_config, bias, prefix)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate_up_proj \u001b[39m=\u001b[39m MergedColumnParallelLinear(\n\u001b[1;32m     71\u001b[0m     input_size\u001b[39m=\u001b[39mhidden_size,\n\u001b[1;32m     72\u001b[0m     output_sizes\u001b[39m=\u001b[39m[intermediate_size] \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[1;32m     73\u001b[0m     bias\u001b[39m=\u001b[39mbias,\n\u001b[1;32m     74\u001b[0m     quant_config\u001b[39m=\u001b[39mquant_config,\n\u001b[1;32m     75\u001b[0m     prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mprefix\u001b[39m}\u001b[39;00m\u001b[39m.gate_up_proj\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_proj \u001b[39m=\u001b[39m RowParallelLinear(input_size\u001b[39m=\u001b[39;49mintermediate_size,\n\u001b[1;32m     77\u001b[0m                                    output_size\u001b[39m=\u001b[39;49mhidden_size,\n\u001b[1;32m     78\u001b[0m                                    bias\u001b[39m=\u001b[39;49mbias,\n\u001b[1;32m     79\u001b[0m                                    quant_config\u001b[39m=\u001b[39;49mquant_config,\n\u001b[1;32m     80\u001b[0m                                    prefix\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mprefix\u001b[39m}\u001b[39;49;00m\u001b[39m.down_proj\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m hidden_act \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msilu\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/layers/linear.py:974\u001b[0m, in \u001b[0;36mRowParallelLinear.__init__\u001b[0;34m(self, input_size, output_size, bias, input_is_parallel, skip_bias_add, params_dtype, reduce_results, quant_config, prefix)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquant_method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 974\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquant_method\u001b[39m.\u001b[39;49mcreate_weights(\n\u001b[1;32m    975\u001b[0m     layer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    976\u001b[0m     input_size_per_partition\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_size_per_partition,\n\u001b[1;32m    977\u001b[0m     output_partition_sizes\u001b[39m=\u001b[39;49m[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_size],\n\u001b[1;32m    978\u001b[0m     input_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_size,\n\u001b[1;32m    979\u001b[0m     output_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_size,\n\u001b[1;32m    980\u001b[0m     params_dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams_dtype,\n\u001b[1;32m    981\u001b[0m     weight_loader\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    982\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_loader_v2 \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquant_method\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m\n\u001b[1;32m    983\u001b[0m         \u001b[39min\u001b[39;49;00m WEIGHT_LOADER_V2_SUPPORTED \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_loader))\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m reduce_results \u001b[39mand\u001b[39;00m (bias \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_bias_add):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vllm/model_executor/layers/linear.py:121\u001b[0m, in \u001b[0;36mUnquantizedLinearMethod.create_weights\u001b[0;34m(self, layer, input_size_per_partition, output_partition_sizes, input_size, output_size, params_dtype, **extra_weight_attrs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_weights\u001b[39m(\u001b[39mself\u001b[39m, layer: torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule,\n\u001b[1;32m    117\u001b[0m                    input_size_per_partition: \u001b[39mint\u001b[39m,\n\u001b[1;32m    118\u001b[0m                    output_partition_sizes: List[\u001b[39mint\u001b[39m], input_size: \u001b[39mint\u001b[39m,\n\u001b[1;32m    119\u001b[0m                    output_size: \u001b[39mint\u001b[39m, params_dtype: torch\u001b[39m.\u001b[39mdtype,\n\u001b[1;32m    120\u001b[0m                    \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_weight_attrs):\n\u001b[0;32m--> 121\u001b[0m     weight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39;49mempty(\u001b[39msum\u001b[39;49m(output_partition_sizes),\n\u001b[1;32m    122\u001b[0m                                    input_size_per_partition,\n\u001b[1;32m    123\u001b[0m                                    dtype\u001b[39m=\u001b[39;49mparams_dtype),\n\u001b[1;32m    124\u001b[0m                        requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m     set_weight_attrs(weight, {\u001b[39m\"\u001b[39m\u001b[39minput_dim\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moutput_dim\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m})\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/_device.py:79\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[0;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 10.57 GiB of which 11.06 MiB is free. Including non-PyTorch memory, this process has 10.55 GiB memory in use. Of the allocated memory 10.21 GiB is allocated by PyTorch, with 23.47 MiB allocated in private pools (e.g., CUDA Graphs), and 55.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m negotiation_env \u001b[39m=\u001b[39m NegotiationEnv(config)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNegotiationEnv initialized\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m train_dataset \u001b[39m=\u001b[39m negotiation_env\u001b[39m.\u001b[39mget_dataset(size\u001b[39m=\u001b[39m\u001b[39m2000\u001b[39m)\n",
      "File \u001b[0;32m~/negotio2/llm-negotiations/envs/negotiation_env.py:39\u001b[0m, in \u001b[0;36mNegotiationEnv.__init__\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame \u001b[39m=\u001b[39m instantiate(config\u001b[39m.\u001b[39mgame)\n\u001b[1;32m     38\u001b[0m \u001b[39m# Instantiate the first agent\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_1 \u001b[39m=\u001b[39m instantiate(config\u001b[39m.\u001b[39;49magent_1)\n\u001b[1;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_2 \u001b[39m=\u001b[39m instantiate(config\u001b[39m.\u001b[39magent_2)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mCONVERT, ConvertMode\u001b[39m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mPARTIAL, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m instantiate_node(\n\u001b[1;32m    227\u001b[0m         config, \u001b[39m*\u001b[39;49margs, recursive\u001b[39m=\u001b[39;49m_recursive_, convert\u001b[39m=\u001b[39;49m_convert_, partial\u001b[39m=\u001b[39;49m_partial_\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m \u001b[39melif\u001b[39;00m OmegaConf\u001b[39m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[39m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:342\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    340\u001b[0m         value \u001b[39m=\u001b[39m node[key]\n\u001b[1;32m    341\u001b[0m         \u001b[39mif\u001b[39;00m recursive:\n\u001b[0;32m--> 342\u001b[0m             value \u001b[39m=\u001b[39m instantiate_node(\n\u001b[1;32m    343\u001b[0m                 value, convert\u001b[39m=\u001b[39;49mconvert, recursive\u001b[39m=\u001b[39;49mrecursive\n\u001b[1;32m    344\u001b[0m             )\n\u001b[1;32m    345\u001b[0m         kwargs[key] \u001b[39m=\u001b[39m _convert_node(value, convert)\n\u001b[1;32m    347\u001b[0m \u001b[39mreturn\u001b[39;00m _call_target(_target_, partial, args, kwargs, full_key)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 value \u001b[39m=\u001b[39m instantiate_node(\n\u001b[1;32m    343\u001b[0m                     value, convert\u001b[39m=\u001b[39mconvert, recursive\u001b[39m=\u001b[39mrecursive\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             kwargs[key] \u001b[39m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mreturn\u001b[39;00m _call_target(_target_, partial, args, kwargs, full_key)\n\u001b[1;32m    348\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[39m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[39m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m convert \u001b[39m==\u001b[39m ConvertMode\u001b[39m.\u001b[39mALL \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    352\u001b[0m         convert \u001b[39min\u001b[39;00m (ConvertMode\u001b[39m.\u001b[39mPARTIAL, ConvertMode\u001b[39m.\u001b[39mOBJECT)\n\u001b[1;32m    353\u001b[0m         \u001b[39mand\u001b[39;00m node\u001b[39m.\u001b[39m_metadata\u001b[39m.\u001b[39mobject_type \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    354\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m full_key:\n\u001b[1;32m     96\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mfull_key: \u001b[39m\u001b[39m{\u001b[39;00mfull_key\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 97\u001b[0m \u001b[39mraise\u001b[39;00m InstantiationException(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target 'models.huggingface_model.HuggingFaceModel':\nOutOfMemoryError('CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 10.57 GiB of which 11.06 MiB is free. Including non-PyTorch memory, this process has 10.55 GiB memory in use. Of the allocated memory 10.21 GiB is allocated by PyTorch, with 23.47 MiB allocated in private pools (e.g., CUDA Graphs), and 55.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)')\nfull_key: experiment.agent_1.model"
     ]
    }
   ],
   "source": [
    "\n",
    "negotiation_env = NegotiationEnv(config)\n",
    "\n",
    "print(\"NegotiationEnv initialized\")\n",
    "\n",
    "train_dataset = negotiation_env.get_dataset(size=2000)\n",
    "test_dataset = negotiation_env.get_dataset(size=200)\n",
    "\n",
    "reward_functions = negotiation_env.get_reward_functions()\n",
    "\n",
    "# notable defaults: lr = 1e-6, max_grad_norm = 0.01, constant lr 10 warmup steps, 1024 tokens in+out\n",
    "run_name = \"grpo_negotiation_test_1\"\n",
    "num_gpus = torch.cuda.device_count()\n",
    "training_args = get_default_grpo_config(run_name=run_name, num_gpus=num_gpus)\n",
    "\n",
    "#Model that should be trained\n",
    "model = negotiation_env.agent_1.model.model_name\n",
    "print(\"Model to be trained:\", model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOEnvTrainer(\n",
    "      model=model,\n",
    "      processing_class=tokenizer,\n",
    "      reward_funcs=reward_functions, \n",
    "      env=negotiation_env,\n",
    "      args=training_args,\n",
    "      train_dataset=dataset\n",
    "  )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
