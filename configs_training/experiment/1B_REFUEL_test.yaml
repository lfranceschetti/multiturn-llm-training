
exp_name: "REFUEL-1B-test"
training_method: REFUEL
seed: 555134
track: true
wandb_project_name: "multiturn_largebatch"
run_name: null
print_sample_output_freq: 100

# Optimizer settings
eps: 1e-8
lr: 3e-7
weight_decay: 1e-6
optimizer: "adamw"
warmup_ratio: 0.1
start_idx: 0
end_idx: -1

gradient_accumulation_steps: 1
per_device_train_batch_size: 1
per_device_eval_batch_size: 2
total_episodes: 1000

# Optional runtime settings
world_size: 1
batch_size: null
local_batch_size: null

# Model paths
base_model: "/cluster/scratch/fraluca/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6"

# Task-specific settings
task:
  query_dataset: "LuckyLukke/NEGOTIO_REFUEL_8B_1000_preprocessed2"
  cluster: ""
  total_length: 2048
  temperature: 0.8

# REFUEL-specific settings
refuel:
  num_updates: 100
  whiten_rewards: false
  shift_mean: false
  eta: 10.0